{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"김자딥파_chapter5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM1WhzPChtEjXBXo+5feCQi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 5.1 단어의 의미\n","\n","- 단어는 겉으로 보이는 형태 내에 의미를 갖는다.\n","- 하나의 형태에 여러 의미가 있기도 하고, 다른 형태의 단어들이 서로 같은 의미를 공유하기도 함\n","- 사람의 언어는 효율성을 추구하도록 진화해와서 모호성이 굉장히 두드러짐\n","- 단어의 모호성 문제는 컴퓨터가 인간의 언어를 이해하고 첯리할 때 매우 큰 과제로 작용\n","\n","### 5.1.1 단어와 의미의 관계\n","\n","- 단어는 겉으로 보이는 형태인 표제어(lemma)안에 여러 의미를 담고 있음\n","- 상황에 따라 각각 다른 의미로 쓰임\n","- 이떄 대부분의 사람은 주변 정보(context)에 따라서 그 숨겨진 의미를 파악하고 이해함\n","- 하지만 주변 정보가 부족하여 모호성이 증가하거나, (자신의 과거 기억 등으로 인하여) 주변 정보를 다르게 해석할 경우에는 사람이라 해도 본래의 의미를 잘못 이해하기도 함\n","- 한 가지 형태의 단어에 여러 의미가 포함되어 생기는 '중의성' 문제는 자연어 처리에서 매우 중요한 위치를 차지\n","\n","### 5.1.2 동형어와 다의어\n","\n","- 형태는 같으나 뜻이 서로 다른 단어를 동형어(homonym)라고 부름\n","    - 동형어는 아예 어원이 다른 의미들이 같은 형태를 띠는 단어\n","- 다의어(polysemy)는 한 형태의 단어가 여러 의미를 지니면서도 그 의미들이 서로 관련이 있는 뜻을 가짐\n","- 이렇게한 형태 내에서 여러 의미를 지니는 동형어 또는 다의어의 경우에는 단어 중의성해소(word-sense disambiguation, WSD)라는 방법을 통해 단어의 의미를 더 명확히 하는 과정이 필요\n","    - 딥러닝 이전의 전통적인 자연어 처리 방식에서는 여러 서브 모듈이 합쳐져 하나의 큰 문제를 해결하는 경우가 많았기 때문에, 서브 모듈들의 처리 과정 중에 단어 중의성 해소 모듈을 포함하여 같이 처리하기도 했음\n","    - 단어의 중의성을 해소하고자 주변 문맥을 통해 원래 단어의 의미를 파악하는 방법을 가장 많이 사용\n","    - 딥러닝의 시대에 들어서는 end-to-end 학습 방법이 선호되고, 자연어 처리 분야에서 주로 사용하는 딥러닝 모델 구조가 순환 신경망(RNN)이 되면서, 단어 중의성 해소에 대한 필요도가 낮아짐\n","    - 하지만 여전히 단어의 모호한 의미로 인해 문제 해결이 어려운 경우가 많아 풀지 못한 숙제 중 하나임\n","\n","### 5.1.3 동의어\n","\n","- 다른 형태이지만 의미가 같은 단어를 동의어(synonym)라고 함\n","\n","### 5.1.4 상위어와 하위어\n","\n","- 사람이 사용하는 단어는 하나의 추상적 개념을 나타냄\n","- 이떄 그 개념들을 포함하는 상위 개념 또는 하위 개념이 존재할 수 있음\n","- 상위 개념을 가리키는 단어를 상위어(hypernym), 하위 개념을 포함하는 단어를 하위어(hyponym)라고 함\n","- 이러한 단어들의 어휘 분류(taxonomy)에 따라 단어 간 관계 구조를 계층화 할 수 있음\n","    - 단어 간의 유사도를 구할 수 있고, 부족한 정보를 비슷한 관계의 다른 단어로부터 얻어올 수도 있음\n","\n","### 5.1.5 모호성 해소\n","\n","- 언어는 그 특징상 겉의 형태는 불연속적 심볼이지만, 내부적으로는 어떤 의미를 가짐\n","- 여러 의미는 하나의 형태를 공유하기도 함\n","- 그 의미들은 매우 다르기도 하고 비슷하기도 함\n","- 하지만 컴퓨터가 가진 것은 텍스트뿐이므로, 그 텍스트가 내포한 진짜 의미를 파악하는 과정이 필요\n","- 단어의 겉 형태인 텍스트만으로는 모호성이 매우 높음\n","- 모호성을 제거함으로써 자연어 처리의 성능을 높일 수 있을 것임\n","- 단어가 가지는 모호성을 제거하는 과정을 단어 중의성 해소(WSD)라고 함\n"],"metadata":{"id":"H_IVIhVbnIDw"}},{"cell_type":"markdown","source":["## 5.2 원핫 인코딩\n","\n","- 단어를 컴퓨터가 인지할 수 있는 수치로 바꾸는 가장 간단한 방법은 벡터로 표현하는 것임\n","- 그 중에서도 가장 기본적인 방법은 원핫 인코딩(one-hot encoding)\n","- 말 그대로 단 하나의 1과 나머지 수많은 0들로 표현된 인코딩 방식을 뜻함\n","- 원핫 인코딩 벡터의 차원은 보통 전체 어휘(vocabulary)의 개수가 되며, 보통 그 숫자는 매우 큰 숫자가 됨(대략 30,000~100,000)\n","- 단어는 불연속적인 심볼로써 이산 확률 변수로 나타냄\n","    - 원핫 벡터는 이산 확률 분포로부터 뽑아낸 샘플이라고 할 수 있음\n","    - 주로 멀티눌리 확률 분포가 될 것임\n","\n","- 문제점\n","    - 벡터의 차원이 너무 큼\n","    - 단 하나의 1을 갖고 나머지는 0으로 가득 참 -> 희소 벡터(sparse vector)\n","        - 희소 벡터의 가장 큰 문제점은 벡터 간(유사도 구하기 등의) 연산을 할 때 결괏값이 0이 된다는 것\n","        - 서로 직교(orthogonal)하는 경우가 많아짐\n","\n","    \n","### 5.2.1 차원의 저주\n","\n","- 정보를 표현하는 데 훨씬 큰 차원이 사용되었다면, 작은 차원으로 같은 정보를 표현한 것에 비해 같은 크기의 공간에 표현되는 정보가 상대적으로 훨씬 적을 것이기 때문\n","- 차원이 늘어날수록 이와 같은 문제가 지수적으로(exponential) 늘어남\n"],"metadata":{"id":"2ttpUvFNo_07"}},{"cell_type":"markdown","source":["## 5.3 시소러스를 활용한 단어 의미 파악\n","\n","- 단어는 내부에 의미를 지니며, 그 의미는 개념과 같아서 계층적 구조를 가짐\n","- 원핫 벡터로는 단어 의미의 특징을 잘 반영할 수 없었음\n","- 만약 그러한 계층적 구조를 잘 분석하고 분류하여 데이터베이스로 구축한다면 자연어 처리를 할 때 매우 큰 도움이 될 것임\n","- 이런 용도로 구축된 데이터베이스를 시소러스(어휘분류사전, thesaurus)라고 부름\n","\n","### 5.3.1 워드넷\n","\n","- 기계번역을 돕기 위한 목적으로 만들어졌으며, 따라서 '동의어 집합' 또는 '상위어'나 '하위어'에 관한 정보가 특히 잘 구축되어 있다는 장점이 있음\n","- 단어에 대한 상위어와 하위어 정보를 구축함으로써, 유향 비순환 그래프(directed acyclic graph, DAG)를 이루게 됨\n","- 트리 구조가 아닌 이유는 하나의 노드가 여러 상위 노드를 가질 수 있기 때문\n","- 워드넷은 단어별 여러 가지 가능한 의미를 미리 정의하고 번호를 매겨 놓았음\n","- 의미별로 비슷한 뜻의 동의어를 링크해 동의어 집합을 제공\n","    - 단어 중의성 해소에 매우 좋은 레이블 데이터가 될 수 있음\n","\n","### 5.3.2 한국어 워드넷\n","\n","|이름|기관|웹사이트|\n","|---|---|---|\n","|KorLex|부산대학교|http://korlex.pusan.ac.kr/|\n","|Korean WordNet(KWN)|KAIST|http://wordnet.kaist.ac.kr/|"],"metadata":{"id":"5bSTo4AszcKv"}},{"cell_type":"markdown","source":["### 5.3.3 워드넷을 활용한 단어간 유사도 비교"],"metadata":{"id":"YBuWJldW1O4c"}},{"cell_type":"code","source":["import nltk\n","nltk.download('wordnet')\n","\n","from nltk.corpus import wordnet as wn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GY94vkDl1P3t","executionInfo":{"status":"ok","timestamp":1646900732715,"user_tz":-540,"elapsed":1075,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"bbb7b12f-7b17-463a-b830-2aafb094dc21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]}]},{"cell_type":"code","source":["def hypernyms(word):\n","    current_node = wn.synsets(word)[0]\n","    yield current_node\n","\n","    while True:\n","        try:\n","            current_node = current_node.hypernyms()[0]\n","            yield current_node\n","        except IndexError:\n","            break"],"metadata":{"id":"8xNL_hBm7Hww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for h in hypernyms('policeman'):\n","    print(h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6wslCQM7WKx","executionInfo":{"status":"ok","timestamp":1646901065596,"user_tz":-540,"elapsed":4,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"c430a0eb-da4f-474d-bb6a-1f70167a0d39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Synset('policeman.n.01')\n","Synset('lawman.n.01')\n","Synset('defender.n.01')\n","Synset('preserver.n.03')\n","Synset('person.n.01')\n","Synset('causal_agent.n.01')\n","Synset('physical_entity.n.01')\n","Synset('entity.n.01')\n"]}]},{"cell_type":"code","source":["for h in hypernyms('firefighter'):\n","    print(h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tcYMFwfF7qEV","executionInfo":{"status":"ok","timestamp":1646901078981,"user_tz":-540,"elapsed":4,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"35a801e2-652e-42e1-dff3-dd07d57c3a77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Synset('fireman.n.04')\n","Synset('defender.n.01')\n","Synset('preserver.n.03')\n","Synset('person.n.01')\n","Synset('causal_agent.n.01')\n","Synset('physical_entity.n.01')\n","Synset('entity.n.01')\n"]}]},{"cell_type":"code","source":["for h in hypernyms('sheriff'):\n","    print(h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOvTl9SR76So","executionInfo":{"status":"ok","timestamp":1646901097939,"user_tz":-540,"elapsed":4,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"088bd8d4-43c7-4e56-e305-57cb3884116f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Synset('sheriff.n.01')\n","Synset('lawman.n.01')\n","Synset('defender.n.01')\n","Synset('preserver.n.03')\n","Synset('person.n.01')\n","Synset('causal_agent.n.01')\n","Synset('physical_entity.n.01')\n","Synset('entity.n.01')\n"]}]},{"cell_type":"code","source":["for h in hypernyms('mailman'):\n","    print(h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LgEcO3209FmK","executionInfo":{"status":"ok","timestamp":1646901107033,"user_tz":-540,"elapsed":3,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"0baa168a-0cec-4312-b256-94cf4bee4ba3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Synset('mailman.n.01')\n","Synset('deliveryman.n.01')\n","Synset('employee.n.01')\n","Synset('worker.n.01')\n","Synset('person.n.01')\n","Synset('causal_agent.n.01')\n","Synset('physical_entity.n.01')\n","Synset('entity.n.01')\n"]}]},{"cell_type":"code","source":["for h in hypernyms('student'):\n","    print(h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iip6UawC9Jaq","executionInfo":{"status":"ok","timestamp":1646901120673,"user_tz":-540,"elapsed":4,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"209eaed8-0b39-4b32-ac62-87e8cf24bd69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Synset('student.n.01')\n","Synset('enrollee.n.01')\n","Synset('person.n.01')\n","Synset('causal_agent.n.01')\n","Synset('physical_entity.n.01')\n","Synset('entity.n.01')\n"]}]},{"cell_type":"markdown","source":["- 시소러스 기반의 정보를 활용하여 단어 간 유사도를 구할 수 있음\n","- 하지만 사전을 구축하는 데는 너무 큰 비용과 시간이 소요\n","- 상위어와 하위어가 잘 반영된 사전이어야만 가능\n","- 사전에 기반한 유사도를 구하는 방식은 비교적 정확한 값을 구할 수 있으나 그 한계가 뚜렷"],"metadata":{"id":"AkW4jT5Y9Mnp"}},{"cell_type":"markdown","source":["## 5.4 특징\n","\n","- 효과적으로 정보를 추출하고 배우려면 어떤 대상의 특징(feature)을 잘 표현해야 함\n","- 특징은 수치로 표현되며, 최대한 많은 샘플을 설명할 수 있어야 함\n","- 샘플들은 수치가 서로 다른 공통된 특징을 가짐\n","- 특징으로 표현된 샘플들은 최대한 다양하게 표현되는게 좋음\n","- 특징별 수치들을 모아 벡터로 표현한 것을 '특징 벡터(feature vector)' 라고 함\n","\n","### 5.4.1 단어의 특징 벡터 구성을 위한 가정\n","\n","1. 의미가 비슷한 단어라면 쓰임새가 비슷할 것\n","2. 쓰임새가 비슷하므로, 비슷한 문장 안에서 비슷한 역할로 사용될 것\n","3. 따라서 함께 나타나는 단어들이 유사할 것"],"metadata":{"id":"3IQjkDs5-ntn"}},{"cell_type":"markdown","source":["## 5.5 특징 추출하기 : TF-IDF\n","\n","$$TF-IDF(w, d) = \\frac{TF(w,d)}{DF(w)}$$\n","\n","- 출현 빈도를 사용하여 어떤 단어 $w$ 가 문서 $d$ 내에서 얼마나 중요한지 나타내는 수치\n","- 이 수치가 높을수록 $w$ 는 $d$ 를 대표하는 성질을 띠게 된다고 볼 수 있음\n","- TF : term frequency 의 약어로, 단어의 문서 내에 출현한 횟수를 의미\n","- IDF : inverse document frequency 의 약어로, 그 단어가 출현한 문서의 숫자의 역수를 의미\n","    - DF 는 해당 단어가 출현한 문서의 수이고, 여기에 inverse 가 붙어 역수를 취한 것임\n","\n","- TF 는 단어가 문서에 출현한 횟수이므로 그 숫자가 클수록 문서에서 중요한 단어일 확률이 높음\n","    - 'the' 와 같은 단어도 TF 값이 매우 클 것임\n","    - 하지만 'the' 가 중요한 경우는 거의 없음\n","    - 이때 IDF 가 필요\n","    - DF 가 큰 값은 일반적으로 많이 쓰이는 단어일 가능성이 높음\n","    - IDF 를 구해 TF 에 곱해줌으로써 'the' 와 같은 단어들에 대한 패널티를 줌\n","\n","- 최종적으로 우리가 얻는 숫자는, 다른 문서들에서는 잘 나타나지 않지만 특정 문서에서만 잘 나타난 경우에 횟수가 높아지므로, 특정 문서에서 얼마나 중요한 역할을 차지하는지 나타내는 수치가 될 수 있음\n","\n","### 5.5.1 TF-IDF 예제\n","\n","- 서로 다른 세 개의 강연 스크립트가 있다고 가정하고, 그중 일부 문장을 분절하여 TF-IDF 를 구해보는 연습\n"],"metadata":{"id":"jQ3MzwNv_P8Y"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"EWSW2cUwAvb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doc1 = '''\n","지능 지수 라는 말 들 어 보 셨 을 겁니다 . 여러분 의 지성 을 일컫 는 말 이 죠 . 그런데 심리 지수 란 건 뭘까요 ? 사람 들 이 특정 한 식 으로 행동 하 는 이유 에 대해 여러분 은 얼마나 알 고 계시 나요 ? 또 타인 이나 심지어 여러분 의 행동 을 예측 하 는 일 은 얼마나 잘 하 시 나요 ? 또 , 심리학 에 대해 갖춘 지식 중 에서 어느 정도 나 잘못 된 것 일까요 ? 심리학 에 관한 열 가지 신화 를 통해 잘못 된 것 들 을 알아보 도록 하 죠 . 여러분 은 한 번 쯤 들 어 보 셨 을 법 한 것 은 자신 들 의 심리학 에 대해 고려 할 때 , 거의 항상 남자 는 화성 에서 왔 고 , 여자 는 금성 에서 온 것 같 다고 합니다 . 하지만 실제로 남자 와 여자 는 얼마나 다른 걸까요 ? 이 를 알아보 기 위해 , 일단 남녀 사이 에 확실 하 게 차이 나 는 것 을 살펴보 고 심리학 적 인 성별 간 의 차이점 을 동일 한 척도 상 에서 대비 해 보 도록 하 겠 습니다 . 남자 와 여자 간 에 실제로 차이 나 는 능력 중 하나 는 그 들 이 공 을 얼마나 멀리 던질 수 있 느냐 하 는 것 입니다 . 여기 남자 들 의 데 이타 를 보 시 면 , 정상 분포 곡선 이 라는 걸 볼 수 있 습니다 . 남자 들 소수 는 정말 멀리 던지 고 , 남자 들 소수 는 멀리 던지 지 못하 지만 , 남자 들 대부분 은 평균 적 인 거리 를 던졌 습니다 . 여자 들 도 역시 비슷 한 분포 상태 를 보입니다 만 사실 남녀 사이 엔 커다란 차이 가 있 습니다 . 사실 , 평균 수준 의 남자 라면 모든 여성 중 대략 98 % 보다 더 멀리 던질 수 있 거든요 . 이 와 동일 하 게 표준 화 된 척도 상 에서 심리학 에서 말 하 는 성별 간 의 차이 를 살펴 봅시다 . 심리학자 라는 여러분 에게 말 하 길 남자 들 의 공간 지각 능력 이 여자 들 보다 뛰어나 다고 할 겁니다 . 예 를 들 어 , 지도 읽 는 능력 같 은 건데 , 맞 는 말 입니다 . 하지만 그 차이 의 정도 를 살펴봅시다 . 아주 작 죠 . 두 선 이 너무 근접 해서 거의 겹칠 정도 입니다 .\n","'''\n","\n","doc2 = '''\n","최상 의 제시 유형 은 학습 자 에 좌우 되 는 것 이 아니 라 학습 해야 할 내용 에 따라 좌우 됩니다 . 예 를 들 어 여러분 이 운전 하 기 를 배울 때 실제로 몸 으로 체감 하 는 경험 없이 누군가 가 어떻게 할 지 이야기 하 는 것 을 듣 는 것 만 으로 배울 수 있 습니까 ? 연립 방정식 을 풀 어야 하 는데 종이 에 쓰 지 않 고 머리 속 에서 말 하 는 것 으로 풀 수 가 있 을까요 ? 또는 만일 여러분 이 체감 형식 의 학습 자 유형 이 라면 , 건축학 시험 을 해석 적 춤 을 이용 하 여 수정 할 수 있 을까요 ? 아니 죠 ! 배워야 할 내용 을 제시 된 유형 에 맞추 어야 합니다 , 당신 에게 맞추 는 게 아니 라요 . 여러분 들 상당수 가 \" A \" 급 의 우등 생 이 라는 걸 아 는데 , 조만간 중등 학력 인증 시험 ( GCSE ) 결과 를 받 게 되 시 겠 네요 . 그런데 , 만일 , 여러분 들 이 희망 했 던 성적 을 받 지 못하 게 된다 해도 여러분 들 의 학습 방식 을 탓 해서 는 안 되 는 겁니다 . 여러분 이 비난 할 수 있 는 한 가지 는 바로 유전자 입니다 . 이건 최근 에 런던 대학교 ( UCL ) 에서 수행 했 던 연구 결과 는 여러 학생 들 과 그 들 의 중등 학력 인증 시험 결과 사이 의 차이 중 58 % 는 유전 적 인 요인 으로 좁혀졌 습니다 . 매우 정밀 한 수치 처럼 들립니다 . 그러면 어떻게 알 수 있 을까요 ? 유전 적 요인 과 환경 적 요인 의 상대 적 기여 도 를 알 고 싶 을 때 우리 가 사용 할 수 있 는 방식 은 바로 쌍둥이 연구 입니다 . 일 란 성 쌍생아 의 경우 환경 적 요인 과 유전 적 요인 모두 를 100 % 똑같이 공유 하 게 되 지만 이란 성 쌍생아 의 경우 는 100 % 동일 한 환경 을 공유 하 지만 유전자 의 경우 여타 의 형제자매 들 처럼 50 % 만 공유 하 게 됩니다 . 따라서 일 란 성 쌍둥이 와 이란 성 쌍둥이 사이 의 인증 시험 결과 가 얼마나 비슷 한지 비교 해 보 고 여기 에 약간 의 수학 적 계산 을 더하 게 되 면 그 수행 능력 의 차이 중 어느 정도 가 환경 적 요인 의 탓 이 고 어느 정도 가 유전자 탓 인지 를 알 수 있 게 됩니다 .\n","'''\n","\n","doc3 = '''\n","그러나 이 이야기 는 세 가지 이유 로 인해 신화 입니다 . 첫째 , 가장 중요 한 건 실험실 가운 은 흰색 이 아니 라 회색 이 었 다 라는 점 이 죠 . 둘째 , 참 여자 들 은 실험 하 기 전 에 와 참여 자 들 이 걱정 을 표현 할 때 마다 상기 시키 는 말 을 들 었 는데 , 전기 충격 이 고통 스럽 기 는 하 지만 , 치명 적 이 지 는 않 으며 실제로 영구 적 인 손상 을 남기 는 일 은 없 을 거 라는 것 이 었 습니다 . 셋째 , 참 여자 들 은 단지 가운 을 입 은 사람 이 시켜 전기 충격 을 주지 는 않 았 죠 . 실험 이 끝나 고 그 들 의 인터뷰 를 했 을 때 모든 참여 자 들 은 강한 신념 을 밝혔 는데 , ' 학습 과 처벌 ' 연구 가 과학 적 으로 가치 있 는 목적 을 수행 했 기 때문 에 비록 동료 참여 자 들 에게 가해진 순간 적 인 불편 함 에 반해서 과학 을 위해서 오래 남 을 성과 를 얻 을 것 이 라고 말 이 죠 . 그러 다 보 니 제 가 이야기 를 한 지 벌써 12 분 이 되 었 습니다 . 여러분 들 중 에 는 아마 거기 앉 아서 제 이야기 를 들으시는 동안 저 의 말투 와 몸짓 을 분석 하 면서 제 가 말 하 는 어떤 것 을 인지 해야 할까 해결 하 려고 하 셨 을 겁니다 , 제 가 진실 을 이야기 하 는 지 , 또는 거짓말 을 하 고 있 는 것 인지 말 이 죠 . 만일 그러 셨 다면 , 아마 지금 쯤 완전히 실패 하 셨 을 겁니다 . 왜냐하면 우리 모두 가 사람 이 말 하 는 패턴 과 몸짓 으로 도 거짓말 여부 를 알아내 는 것 이 가능 하 다고 생각 하 지만 , 오랜 세월 수백 회 에 걸쳐 행해진 실제 심리 검사 의 결과 를 보 면 우리 들 모두 는 , 심지어 경찰관 이나 탐정 들 을 포함 해서 도 기본 적 으로 몸짓 과 언어 적 패턴 으로 거짓말 을 탐지 하 는 것 은 운 에 맞 길 수 밖 에 는 없 는 것 입니다 . 흥미 롭 게 도 한 가지 예외 가 있 는데요 : 실종 된 친척 을 찾 아 달 라고 호소 하 는 TV 홍보 입니다 .\n","'''"],"metadata":{"id":"0THFhzgdDG--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_term_frequency(document, word_dict=None):\n","    if word_dict is None:\n","        word_dict = {}\n","    words = document.split()\n","\n","    for w in words:\n","        word_dict[w] = 1 + (0 if word_dict.get(w) is None else word_dict[w])\n","\n","    return pd.Series(word_dict).sort_values(ascending=False)"],"metadata":{"id":"FHNjUs5EAwwm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_term_frequency(doc1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWoI9J7oDRc-","executionInfo":{"status":"ok","timestamp":1646902719914,"user_tz":-540,"elapsed":3,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"a94eee84-e446-4785-8f1e-97fe83bfcf25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[".     16\n","는     15\n","들     14\n",",     10\n","하     10\n","      ..\n","고려     1\n","자신     1\n","법      1\n","쯤      1\n","겹칠     1\n","Length: 186, dtype: int64"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["def get_document_frequency(documents):\n","    dicts = []\n","    vocab = set([])\n","    df = {}\n","\n","    for d in documents:\n","        tf = get_term_frequency(d)\n","        dicts += [tf]\n","        vocab = vocab | set(tf.keys())\n","\n","    for v in list(vocab):\n","        df[v] = 0\n","        for dict_d in dicts:\n","            if dict_d.get(v) is not None:\n","                df[v] += 1\n","\n","    return pd.Series(df).sort_values(ascending=False)"],"metadata":{"id":"cV6G2yQbBEn6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_document_frequency([doc1, doc2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOzRUkyuDa0e","executionInfo":{"status":"ok","timestamp":1646902760166,"user_tz":-540,"elapsed":4,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"96a63475-1d79-466e-c060-c7f164361ba4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["것      2\n","한      2\n","동일     2\n","보      2\n","예      2\n","      ..\n","그러면    1\n","이용     1\n","제시     1\n","싶      1\n","머리     1\n","Length: 311, dtype: int64"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["def get_tfidf(docs):\n","    vocab = {}\n","    tfs = []\n","    for d in docs:\n","        vocab = get_term_frequency(d, vocab)\n","        tfs += [get_term_frequency(d)]\n","    df = get_document_frequency(docs)\n","\n","    from operator import itemgetter\n","    import numpy as np\n","\n","    stats = []\n","    for word, freq in vocab.items():\n","        tfidfs = []\n","        for idx in range(len(docs)):\n","            if tfs[idx].get(word) is not None:\n","                tfidfs += [tfs[idx][word] * np.log(len(docs) / df[word])]\n","            else:\n","                tfidfs += [0]\n","\n","        stats.append((word, freq, *tfidfs, max(tfidfs)))\n","\n","    return pd.DataFrame(stats, columns=('word',\n","                                        'frequency',\n","                                        'doc1',\n","                                        'doc2',\n","                                        'doc3',\n","                                        'max')).sort_values('max', ascending=False)"],"metadata":{"id":"FjtDSpTuB7WH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_tfidf([doc1, doc2, doc3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"bbLGxoN2Cr2q","executionInfo":{"status":"ok","timestamp":1646902783108,"user_tz":-540,"elapsed":453,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"0be746f4-44a1-4a7f-fdf0-ccb4e0e1c388"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-47dd7eaa-b83b-41bf-a664-2796010c7bce\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>frequency</th>\n","      <th>doc1</th>\n","      <th>doc2</th>\n","      <th>doc3</th>\n","      <th>max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>23</th>\n","      <td>남자</td>\n","      <td>9</td>\n","      <td>9.887511</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>9.887511</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>요인</td>\n","      <td>6</td>\n","      <td>0.000000</td>\n","      <td>6.591674</td>\n","      <td>0.000000</td>\n","      <td>6.591674</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>심리학</td>\n","      <td>5</td>\n","      <td>5.493061</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.493061</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>성</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>었</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.394449</td>\n","      <td>4.394449</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>라는</td>\n","      <td>6</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>와</td>\n","      <td>6</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>습니다</td>\n","      <td>7</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>보</td>\n","      <td>7</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>는</td>\n","      <td>47</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>437 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47dd7eaa-b83b-41bf-a664-2796010c7bce')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-47dd7eaa-b83b-41bf-a664-2796010c7bce button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-47dd7eaa-b83b-41bf-a664-2796010c7bce');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   word  frequency      doc1      doc2      doc3       max\n","23   남자          9  9.887511  0.000000  0.000000  9.887511\n","37   요인          6  0.000000  6.591674  0.000000  6.591674\n","52  심리학          5  5.493061  0.000000  0.000000  5.493061\n","66    성          4  0.000000  4.394449  0.000000  4.394449\n","57    었          4  0.000000  0.000000  4.394449  4.394449\n","..  ...        ...       ...       ...       ...       ...\n","35   라는          6  0.000000  0.000000  0.000000  0.000000\n","34    와          6  0.000000  0.000000  0.000000  0.000000\n","30  습니다          7  0.000000  0.000000  0.000000  0.000000\n","29    보          7  0.000000  0.000000  0.000000  0.000000\n","0     는         47  0.000000  0.000000  0.000000  0.000000\n","\n","[437 rows x 6 columns]"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["## 5.6 특징 벡터 만들기\n","\n","### 5.6.1 TF 행렬 만들기\n","\n","- 단어의 문서별 출현 횟수를 가리키는 TF(term frequency) 또한 훌륭한 특징이 될 수 있음\n","- 어떤 단어가 문서마다 출현한 횟수가 차원별로 구성되면, 하나의 특징 벡터를 이룰 수 있음"],"metadata":{"id":"2xlmBzT2DgpK"}},{"cell_type":"code","source":["def get_tf(docs):\n","    vocab = {}\n","    tfs = []\n","    for d in docs:\n","        vocab = get_term_frequency(d, vocab)\n","        tfs += [get_term_frequency(d)]\n","\n","    from operator import itemgetter\n","    import numpy as np\n","\n","    stats = []\n","    for word, freq in vocab.items():\n","        tf_v = []\n","        for idx in range(len(docs)):\n","            if tfs[idx].get(word) is not None:\n","                tf_v += [tfs[idx][word]]\n","            else:\n","                tf_v += [0]\n","        stats.append((word, freq, *tf_v))\n","\n","    return pd.DataFrame(stats, columns=('word',\n","                                        'frequency',\n","                                        'doc1',\n","                                        'doc2',\n","                                        'doc3')).sort_values('frequency', ascending=False)"],"metadata":{"id":"cv58ceDxEhHx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_tf([doc1, doc2, doc3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"vwgrm7jNEzZf","executionInfo":{"status":"ok","timestamp":1646903344687,"user_tz":-540,"elapsed":615,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"b8f28264-8bb5-446f-dbee-babf07e9d82e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-1622bc14-8e07-46de-8ed2-f0865aeb9bc1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>frequency</th>\n","      <th>doc1</th>\n","      <th>doc2</th>\n","      <th>doc3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>는</td>\n","      <td>47</td>\n","      <td>15</td>\n","      <td>14</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>을</td>\n","      <td>39</td>\n","      <td>8</td>\n","      <td>10</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>.</td>\n","      <td>36</td>\n","      <td>16</td>\n","      <td>10</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>하</td>\n","      <td>33</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>이</td>\n","      <td>32</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>273</th>\n","      <td>항상</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>274</th>\n","      <td>반해서</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>275</th>\n","      <td>위해서</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>276</th>\n","      <td>오래</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>436</th>\n","      <td>홍보</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>437 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1622bc14-8e07-46de-8ed2-f0865aeb9bc1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1622bc14-8e07-46de-8ed2-f0865aeb9bc1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1622bc14-8e07-46de-8ed2-f0865aeb9bc1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    word  frequency  doc1  doc2  doc3\n","0      는         47    15    14    18\n","1      을         39     8    10    21\n","2      .         36    16    10    10\n","3      하         33    10     9    14\n","4      이         32     8     8    16\n","..   ...        ...   ...   ...   ...\n","273   항상          1     1     0     0\n","274  반해서          1     0     0     1\n","275  위해서          1     0     0     1\n","276   오래          1     0     0     1\n","436   홍보          1     0     0     1\n","\n","[437 rows x 5 columns]"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["### 5.6.2 콘텍스트 윈도우로 함께 출현한 단어들의 정보 활용하기\n","\n","- 의미가 비슷한 단어라면 쓰임새 역시 비슷할 것이다.\n","- 쓰임새가 비슷하기에 비슷한 문장 안에서 비슷한 역할로 사용될 것이다.\n","- 함께 나타나는 단어들이 서로 유사할 것이다.\n","- 함께 나타나는 단어들을 조사하기 위해 윈도잉(windowing)을 실행\n","    - 윈도잉이란 윈도우를 움직이며 그 안에 있는 유닛들의 정보를 취합하는 방법을 이르며 이때 사용되는 윈도우를 컨텍스트 윈도우(context window)라고 함\n","    - 단어별로 윈도우 내에 속해 있는 이웃 단어들의 출현 빈도를 세어 행렬로 나타내는 것\n","\n","- TF 로 특징 벡터를 구성한 방식보다 더 정확하다고 할 수 있음\n","- 하지만 '윈도우 크기'라는 하나의 하이퍼파라미터가 추가되므로 사용자가 그 값을 정해주어야 함\n","    - 적절한 윈도우 크기를 정하는 것이 중요\n","    - 문제에 따라 다르겠지만 대부분의 경우에는 윈도우를 문장 내에만 적용\n","\n"],"metadata":{"id":"_DqBY_3uE1WJ"}},{"cell_type":"code","source":["from collections import defaultdict\n","\n","import pandas as pd"],"metadata":{"id":"CP6VOdDiZh_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_context_counts(lines, w_size=2):\n","    co_dict = defaultdict(int)\n","\n","    for line in lines:\n","        words = line.split()\n","\n","        for i, w in enumerate(words):\n","            for c in words[i - w_size:i + w_size]:\n","                if w != c:\n","                    co_dict[(w, c)] += 1\n","\n","    return pd.Series(co_dict)"],"metadata":{"id":"aj42FnkxZk5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def co_occurrence(co_dict, vocab):\n","    data = []\n","\n","    for word1 in vocab:\n","        row = []\n","\n","        for word2 in vocab:\n","            try:\n","                count = co_dict[(word1, word2)]\n","            except KeyError:\n","                count = 0\n","            row.append(count)\n","\n","        data.apped(row)\n","\n","    return pd.DataFrame(data, index=vocab, coluns=vocab)"],"metadata":{"id":"LCcIpDAlZxVf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 출현 빈도가 높은 단어들은 대부분 값이 잘 채워져 있음\n","- 하지만 출현 빈도가 낮은 단어들은 많은 부분이 0으로 채워져 있음\n","- 이런 희소 벡터들이 많으면, 유사도를 구하거나 벡터간 연산을 할 때 직교하는 경우가 많아 매우 곤란\n"],"metadata":{"id":"xWaL-bbMaLwC"}},{"cell_type":"markdown","source":["## 5.7 벡터 유사도 구하기\n","\n","- 단어들은 겉의 불연속적인 형태와 달리 내부적으로 의미를 지님\n","- 이에 따라 단어들은 서로 유사성을 지님\n","- 특징 벡터는 단어 사이의 유사도를 구할 때 아주 유용함\n","\n","### 5.7.1 L1 거리\n","\n","- L1 거리 : L1 norm 을 사용한 것으로 맨해튼 거리(Manhattan distance)라고도 함\n","- 두 벡터의 각 차원별 값의 차이의 절대값을 모두 합한 값\n","\n","$$ d_{L1}(w, v) = \\sum^{d}_{i=1}\\vert w_i - v_i \\vert, where w, v \\in \\mathbb{R}^d $$\n"],"metadata":{"id":"eQrEB3AkduXa"}},{"cell_type":"code","source":["def get_l1_distance(x1, x2):\n","    return ((x1 - x2).abs()).sum()"],"metadata":{"id":"V-sNjr0pef5w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.7.2 L2 거리\n","\n","- L2 거리 : 유클리디안 거리(Euclidean distance)\n","- 차원별 값 차이의 제곱의 합에 루트를 취한 형태\n","\n","$$ d_{L2}(w, v) = \\sqrt{\\sum^{d}_{i=1}(w_i - v_i)^2}, \\text{where}\\, w, v \\in \\mathbb{R}^d $$"],"metadata":{"id":"CpT3_eAgegVM"}},{"cell_type":"code","source":["def get_l2_distance(x1, x2):\n","    return ((x1 - x2)**2).sum()**.5"],"metadata":{"id":"HWuvDOC3egZC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.7.3 infinity Norm\n","\n","- L1, L2 거리가 있다면 $L_{\\infty}$ 거리도 있음\n","- 차원별 값의 차이 중 가장 큰 값을 나타냄"],"metadata":{"id":"CR9p2Y1Uegbq"}},{"cell_type":"code","source":["def get_infinity_distance(x1, x2):\n","    return ((x1 - x2).abs()).max()"],"metadata":{"id":"HhpNPUrVegej"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.7.4 코사인 유사도\n","\n","- 두 벡터 사이의 방향과 크기를 모두 고려하는 방법\n","\n","$$ \\text{sim}_{cos}(w, v) = \\frac{w \\cdot v}{\\vert w \\vert \\vert v \\vert} = \\frac{w}{\\vert w \\vert} \\cdot \\frac{v}{\\vert v \\vert} \\\\ = \\frac{\\displaystyle\\sum^{d}_{i=1}w_iv_i}{\\displaystyle\\sqrt{\\sum^{d}_{i=1}w_i^2}\\sqrt{\\sum^{d}_{i=1}v_i^2}} \\\\ \\text{where} \\, w, v \\in \\mathbb{R}^d $$\n","\n","- 수식의 윗변은 두 벡터 사이의 요소별(element-wise)곱을 사용하므로 벡터의 내적과 같음\n","- 코사인 유사도의 결과가 1에 가까울수록 방향은 일치하고 0에 가까울수록 직교이며 -1에 가까울수록 반대 방향임을 의미\n","- 하지만 벡터 내적 연산이나 밑변 각 벡터의 크기(L2 norm)를 구하는 연산이 비싼 편\n","- 벡터 차원의 크기가 클수록 연산량이 부담\n","- 희소 벡터일 경우 여기서 가장 큰 문제가 나타남\n","    - 윗변이 벡터 곱으로 표현되므로 0이 들어간 차원이 많으면 해당 차원이 직교하면서 곱의 값이 0이 됨\n","    - 정확한 유사도 또는 거리를 반영하지 못함"],"metadata":{"id":"NPOd8Um3eghY"}},{"cell_type":"code","source":["def get_cosine_similarity(x1, x2):\n","    return (x1 * x2).sum() / ((x1**2).sum()**.5 * (x2**2).sum()**.5)"],"metadata":{"id":"oUiokzRVegkE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.7.5 자카드 유사도\n","\n","- 두 집합 간의 유사도를 구하는 방법\n","\n","$$ \\text{sim}_{jacard}(w, v) = \\frac{\\vert w \\cap v \\vert}{\\vert w \\cup v \\vert} \\\\ = \\frac{\\vert w \\cap v \\vert}{\\vert w \\vert + \\vert v \\vert - \\vert w \\cap v \\vert} \\\\ \\approx \\frac{\\displaystyle\\sum_{i=1}^{d} \\min (x_i, v_i)}{\\displaystyle\\sum_{i=1}^{d}\\max (w_i, v_i)} \\\\ \\text{where}\\, w, v \\in \\mathbb{R}^d $$\n","\n","- 수식의 윗변에는 두 집합의 교집합 크기가 있고, 이를 밑변에서 두 집합의 합집합 크기로 나눈다.\n","- 이때 특징 벡터의 각 차원이 집합의 요소(element)가 됨\n","- 다만, 각 차원에서의 값이 0 또는 0이 아닌 값이 아니라 수치 자체에 대해 자카드 유사도를 구하고자 할 때는, 두 번쨰 줄의 수식과 같이 두 벡터의 각 치원의 숫자에 대해 min, max 연산을 통해서 계산할 수 있음"],"metadata":{"id":"SILU3gb7egmt"}},{"cell_type":"code","source":["import torch \n","\n","def get_jaccard_similarity(x1, x2):\n","    return torch.stack([x1, x2]).min(dim=0)[0].sum() / torch.stack([x1, x2]).max(dim=0)[0].sum()"],"metadata":{"id":"8XfML0lZegpi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x1 = torch.tensor([0, 1, 2])\n","x2 = torch.tensor([3, 4, 5])\n","torch.stack([x1, x2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFOt3pDSegsV","executionInfo":{"status":"ok","timestamp":1646962357909,"user_tz":-540,"elapsed":259,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"f13f5d25-3fd5-4608-ecdb-73d5beae1405"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 1, 2],\n","        [3, 4, 5]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["torch.stack([x1, x2]).min(dim=0)[0].sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njfV2JUCegvN","executionInfo":{"status":"ok","timestamp":1646962395703,"user_tz":-540,"elapsed":361,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"64201478-ce0f-4b96-e928-c99dcf6d42fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3)"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["### 5.7.6 문서 간 유사도 구하기\n","\n","- 단어들이 모여 하나의 문장을 이루고, 문장들이 모여 하나의 문서를 이룸\n","- 문서는 더 많은 단어의 집합이라고 할 수 있음\n","- 문서에 대해 특징을 추출하여 문서간의 유사도를 구할 수 있음\n"],"metadata":{"id":"43u4W2Ggegxz"}},{"cell_type":"markdown","source":["## 5.8 단어 중의성 해소\n","\n","- 하나의 단어는 여러 가지 의미를 지닐 수 있음\n","- 서로 비슷한 의미의 다의어인 경우에는 비교적 그 문제가 크지 않을 수 있음\n","    - 조금은 어색한 문장 표현이 될 수 있겠지만, 큰 틀에서는 벗어나지 않기 때문\n","- 하지만 동형어의 경우에는 문제가 커짐\n","    - '차'의 경우 'tea'로 해석되느냐 'car'로 해석되느냐에 따라 문장의 의미가 매우 달라짐\n","\n","### 5.8.1 시소러스 기반 중의성 해소: 레스크 알고리즘\n","\n","- 가장 간단한 사전 기반 중의성 해소 방법\n","- 주어진 문장에서 특정 단어의 의미를 명확히 할 때 사용할 수 있음\n","- 가정을 하나 만든다.\n","    - 문장 내에 같이 등장하는 단어들은 공통 토픽을 공유한다\n","\n","- 레스크 알고리즘\n","    1. 중의성을 해소하고자 하는 단어에 대해 사전(주로 워드넷)의 의미별 설명과, 주어진 문장 내에 등장한 단어의 사전에서 의미별 설명 사이의 유사도를 구함\n","        - 유사도를 구하는 방법은여러가지가 있겠지만, 가장 간단한 방법으로는 겹치는 단어의 개수를 구함\n","    2. 문장 내 단어들의 의미별 설명과 가장 유사도가 높은 (또는 겹치는 단어가 많은) 의미를 선택"],"metadata":{"id":"F8S4bnCZeg0r"}},{"cell_type":"code","source":["import nltk\n","nltk.download('wordnet')"],"metadata":{"id":"uzFkFqzoqWqk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예를들어 NLTK 의 워드넷에 'bass'를 검색해보면 다음과 같음\n","from nltk.corpus import wordnet as wn\n","\n","for ss in wn.synsets('bass'):\n","    print(ss, ss.definition())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZD8ZqvHXeg3l","executionInfo":{"status":"ok","timestamp":1646963292387,"user_tz":-540,"elapsed":263,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"72cba883-65ca-4cd5-d2b7-23452c119456"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Synset('bass.n.01') the lowest part of the musical range\n","Synset('bass.n.02') the lowest part in polyphonic music\n","Synset('bass.n.03') an adult male singer with the lowest voice\n","Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n","Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n","Synset('bass.n.06') the lowest adult male singing voice\n","Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n","Synset('bass.n.08') nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n","Synset('bass.s.01') having or denoting a low vocal or instrumental range\n"]}]},{"cell_type":"code","source":["# 레스크 알고리즘 수행을 위하여 간단하게 감싸 구현하겠습니다.\n","def lesk(sentence, word):\n","    from nltk.wsd import lesk\n","\n","    best_synset = lesk(sentence.split(), word)\n","    print(best_synset, best_synset.definition())"],"metadata":{"id":"C0oBF9bVeg6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 다음과 같이 주어진 문장에서 'bass'의 의미는 물고기입니다.\n","sentence = 'I went fishing last weekend and I got a bass and cooked it'\n","word = 'bass'\n","lesk(sentence, word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"toXhqefweg9Y","executionInfo":{"status":"ok","timestamp":1646963655626,"user_tz":-540,"elapsed":254,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"c5e9acaa-8bd0-4ded-d6b7-f909b520a771"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"]}]},{"cell_type":"code","source":["# 또한, 다음 문장에서는 '음악에서의 역할'을 의미하는 것으로 추정됩니다.\n","sentence = 'I love the music from the speaker which has strong beat and bass'\n","word = 'bass'\n","lesk(sentence, word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M51nFbInePm0","executionInfo":{"status":"ok","timestamp":1646963718916,"user_tz":-540,"elapsed":264,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"86dd9853-0866-45bc-d17b-d1c16919dc8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Synset('bass.n.02') the lowest part in polyphonic music\n"]}]},{"cell_type":"code","source":["# 비교적 정확하게 예측해낸 아의 두 사례와 달리, 다음 문장에서는 전혀 다른 의미로 예측하는 것을 볼 수 있음\n","sentence = 'I think the bass is more important than guitar'\n","word = 'bass'\n","lesk(sentence, word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t04DZvdFr_cv","executionInfo":{"status":"ok","timestamp":1646963788875,"user_tz":-540,"elapsed":4,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"c5fbabb0-dfcf-4ff9-cd4e-37c6e4b4e5ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"]}]},{"cell_type":"markdown","source":["- 레스크 알고리즘은 명확한 장단점을 지님\n","    - 장점\n","        - 워드넷과 같이 잘 분류된 사전이 있다면, 쉽고 빠르게 중의성 해소 문제를 해결할 수 있음\n","        - 워드넷에서 이미 단어별로 몇 개의 의미를 지니는지 잘 정의해 두었기에 크게 고민할 필요도 없음\n","    - 단점\n","        - 사전의 단어 및 의미에 관한 설명에 크게 의존하게 되고, 설명이 부실하거나 주어진 문장에 큰 특징이 없을 경우 단어 중의성 해소 능력은 크게 떨어짐\n","        - 워드넷이 모든 언어에 대해 존재하지 않으므로, 사전이 존재하지 않는 언어에 대해서는 레스크 알고리즘 자체의 수행이 어려울 수 있음"],"metadata":{"id":"jBfWwV0osQm-"}},{"cell_type":"markdown","source":["## 5.9 선택 선호도\n","\n","- 문장은 여러 단어의 시퀀스로 이루어짐\n","- 각 단어는 문장 내 주변의 단어들에 따라 그 의미가 정해지기 마련임\n","- 선택 선호도는 이를 더 수치화하여 나타냄\n","\n","### 5.9.1 선택 선호도 강도\n","\n","- 단어와 단어 사이의 관계가 좀 더 특별한 경우를 수치화하여 나타냄\n","- 술어 동사(predicate verb)가 주어졌을 때, 목적어 관계에 있는(보통은 명사인) 표제어(headword) 단어들의 분포는 평소 문서 내에 해당 명사가 나올 분포와는 다를 것임\n","- 쿨백-라이블러 발산(KLD)을 사용하여 정의했음\n","\n","$$ \\text{S}_R(w) = \\text{KL}(P(C \\vert w) \\Vert P(C)) \\\\ = -\\sum_{c \\in C} P(c \\vert w)\\log \\frac{P(C)}{P(c \\vert w)} \\\\ = -\\mathbb{E}_{c~P(C \\vert w)}[\\log\\frac{P(C)}{P(C \\vert W=w)}] $$\n","\n","- 선택 선호도 강도 $S_R(w)$ 은 $w$ 가 주어졌을때의 오브젝트 클래스 C 의 분포 $P(C \\vert w)$ 와 그냥 해당 클래스들의 사전 분포 $P(C)$ 와의 KLD 로 정의되어 있음\n","- 선택 선호도 강도는 술어가 표제어로 특정 클래스를 얼마나 선택적으로 선호하는지에 대한 수치라고 할 수 있음\n","\n","### 5.9.2 선택 관련도\n","\n","$$ A_R(w, c) = - \\frac{P(c \\vert w)\\log\\frac{P(c)}{P(c \\vert w)}}{S_R(w)} $$\n","\n","- 선택 선호도 강도가 낮은 술어에 대해서 윗변의 값이 클 경우에는 술어와 클래스 사이에 더 큰 선택 관련도를 갖는다\n","- 선택 선호도 강도가 낮아서, 해당 술어는 클래스에 대한 선택적 선호 강도가 낮음에도 불구하고, 특정 클래스만 유독 술어에 영향을 받아서 윗변이 커질수록 선택 관련도의 수치도 커짐"],"metadata":{"id":"gF8VcpSHso3e"}},{"cell_type":"markdown","source":["음 크게 쓰이지 않는 개념인듯하여 다음장으로 넘어가겠음"],"metadata":{"id":"NT50V25zdZkb"}},{"cell_type":"code","source":[""],"metadata":{"id":"VMQUkPPAdiDk"},"execution_count":null,"outputs":[]}]}