{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"김자딥파_chapter6.ipynb","provenance":[],"authorship_tag":"ABX9TyOu8pSiZx5jsLX56HU4X1oA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 6.2 차원 축소\n","\n","### 6.2.1 주성분 분석\n","\n","- 대표적인 차원 축소방법인 주성분 분석(principal component analysis, PCA)\n","- 고차원의 데이터를 더 낮은 차원으로 표현할 수 있음\n","- 특잇값 분해(singular value decomposition, SVD)를 통해 주성분을 분석할 수 있음\n","- 고차원에서 주어진 데이터들을 임의의 주성분, 고차원 평면(초평면)에 투사했을 때 투사점들 사이가 서로 최대한 멀어져야 함\n","    - 즉, 투사점들의 분산이 최대가 되도록 함\n","- 고차원 평면으로 투사할 때 원래 벡터와 고차원 평면상의 투사된거리가 최소가 되어야 함\n","\n","- 고차원의 데이터를 더 낮은 차원으로 효과적으로 압축할 수 있음\n","- 하지만 실제 데이터(점)의 위치와 고차원 평면에 투사된 점의 거리가 생길 수 밖에 없음\n","    - 이는 곧 정보의 손실을 의미\n","    - 너무 많은 정보가 손실된다면 효율적으로 정보를 학습하거나 복구할 수 없음\n","- 따라서 높은 차원에 표현된 정보를 지나치게 낮은 차원으로 축소하여 표현하기는 어려움\n","    - 특히 데이터가 비선형적으로 구성될수록 더욱 어려워짐\n","\n","### 6.2.2 매니폴드 가설\n","\n","- 높은 차원에 존재하는 데이터들의 경우, 실제로는 해당 데이터들을 아우르는 낮은 차원의 다양체(manifold) 역시 존재한다는 가설\n","- 매니폴드를 찾아 2차원 평면에 데이터 포인트들을 맵핑할 수 있다면 주성분 분석처럼 데이터를 고차원 평면에 선형적으로 투사하며 생긴 손실을 최소화 할 수 있음\n","\n","- 고차원상에서 가까운 거리에 있던 데이터 포인트들일지라도, 매니폴드를 보다 저차원 공간으로 맵핑하면 오히려 거리가 멀어질 수 있다\n","- 저차원의 공간상에서 가까운 점끼리는 실제로도 비슷한 특징을 갖는다\n","    - 저차원의 각 공간의 차원축은 고차원에서 비선형적으로 표현될 것이며, 데이터의 특징을 각각 표현하게 될 것임\n","\n","### 6.2.3 딥러닝이 잘 동작하는 이유\n","\n","- 대부분의 경우 딥러닝이 문제를 풀기 위해 차원 축소를 수행하는 과정은, 데이터가 존재하는 고차원상에서 매니폴드를 찾는 과정임\n","- 주성분 분석과같이 다른 선형적인 방식에 비해 딥러닝은 비선형적인 방식으로 차원 축소를 수행하며, 그 과정에서 해당 문제를 가장 잘 해결하기 위한 매니폴드를 자연스럽게 찾아냄\n","\n","### 6.2.4 오토인코더\n","\n","- 고차원의 샘플 벡터를 입력으로 받아 매니폴드를 찾고, 저차원으로 축소하는 인코더를 거쳐 병목(bottle-neck) 구간에서의 숨겨진(hidden) 벡터로 표현\n","- 디코더는 저차원의 벡터를 받아, 다시 원래 입력 샘플이 존재하던 고차원으로 데이터를 복원하는 작업을 수행\n","- 복원된 데이터는 고차원 상의 매니폴드 위에 위치하게 됨\n","\n","\n","- 오토인코더는 병목의 차원이 매우 낮기 때문에 복원에 필요한 정보만 남기고 필요 없는 정보는 버려야 함\n","    -  복원에 필요 없는 정보부터 버려질 것임\n","- 이 구조의 모델을 훈련할 때는 복원된 데이터와 실제 입력 데이터 사이의 차이를 최소화하도록 손실 함수를 구성함\n","\n"],"metadata":{"id":"QwHEu09Ud-cQ"}},{"cell_type":"markdown","source":["## 6.3 흔한 오해1\n","\n","- 훈련한 단어 임베딩 벡터를 추후 우리가 다룰 텍스트 분류, 언어 모델, 번역 등의 딥러닝 모델 입력으로 사용하리라 생각한다는 점\n","- 이 임베딩 벡터를 사전 훈련(pre-training)된 임베딩 벡터라고 함\n","- word2vec 을 통해 얻은 단어 임베딩 벡터가 훌륭하게 단어의 특징을 잘 반영하고 있긴 하지만, 텍스트 분류나 언어 모델, 번역의 문제를 해결하는 최적의 벡터 임베딩이라고는 볼 수 없음\n","- 다시 말하면, 텍스트 분류 또는 기계번역을 위한 목적 함수는 분명히 word2vec 과 다른 형태로 존재함\n","- 따라서 다른 목적 함수를 통해 훈련한 임베딩 벡터는 원래의 목적에 맞지 않을 가능성이 높음\n","\n","- 문제의 특징을 고려하지 않은 단어 임베딩 벡터는 그다지 좋은 방법이 될 수 없음\n","\n","### 6.3.1 word2vec 없이 신경망 훈련하기\n","\n","- word2vec 을 사용하여 단어를 저차원의 임베딩 벡터로 변환하지 않아도, 문제의 특징에 맞는 단어 임베딩을 구할 수 있음\n","\n","$$ y = emb(x) = Wx, \\\\ \\text{where}\\, W \\in \\mathbb{R}^{d \\times \\vert V \\vert} \\text{and} \\vert V \\vert \\text{is size of vocabulary.} $$\n","\n","- 여러 딥러닝 프레임워크는 임베딩 계층(embedding layer)이라는 레이어 아키텍처를 제공함\n","- 이 계층은 편차(bias)가 없는 선형 계층과 같은 형태를 지님\n","- $W$ 는 $d \\times \\vert V \\vert$ 크기의 2차원 행렬임\n","- 입력으로 원핫 벡터가 주어지면, $W$ 의 특정 행(구현 방법에 따라서는 특정 열)만 반환함\n","\n","- 최종적으로 모델으로부터 구한 솔실값에 따라 역전파 및 경사하강법을 수행하면, 자동적으로 임베딩 계층의 가중치(weight)인 $W$ 의 값을 구할 수 있을 것임\n","\n","- 실제 구현에서는 이렇게 큰 임베딩 계층 가중치와 원핫 인코딩 벡터를 곱하는 것은 매우 비효율적이므로, 단순히 테이블에서 검색(lookup)하는 작업을 수행함\n","- 따라서 단어를 나타낼 때(임베딩 계층의 입력으로) 원핫 벡터를 굳이 넘겨줄 필요 없이, 1이 존재하는 단어의 인덱스 정숫값만 입력으로 넘겨주면 임베딩 벡터를 얻을 수 있음\n","\n","- 추후 다룰 텍스트 분류나 기계번역 장에서 구현한 내용을 살펴보면, word2vec 을 사용하여 단어를 임베딩 벡터로 변환한 후 신경망에 직접 넣는 대신, 앞에서 언급한 것처럼 임베딩 계층을 사용하여 원핫 인코딩 벡터를 입력으로 넣도록 구현했음을 알 수 있음\n","\n","### 6.3.2 그래도 word2vec 적용하는 경우\n","\n","- 준비된 코퍼스의 양이 너무 적고, 이때 외부로부터 많은 양의 말뭉치를 통해 미리 훈련한 단어 임베딩 벡터를 구한다는 특수한 경우를 가정해볼 수 있음\n","- 기본 정석대로 먼저 베이스라인 모델을 만든 후, 성능을 끌어올리기 위한 여러 가지 방법들을 시도할 때 사전 훈련된 단어 임베딩 벡터의 사용을 고려해볼 수 있음\n","- 전이학습(transfer learning)에서 살펴볼 고도화된 언어 모델을 통해 사전 훈련하여 접근해볼 수도 있음"],"metadata":{"id":"-xTcZBd8pPks"}},{"cell_type":"markdown","source":["## 6.4 word2vec\n","\n","- word2vec 을 임베딩하는 두 가지 방법으로 CBOW 와 Skip-gram 가 있음\n","    - CBOW : 주변 단어로 가운데 단어를 예측\n","    - Skip-gram : 가운데 단어로 주변 단어를 예측\n","\n","- 두 방법 모두 함께 등장하는 단어가 비슷할수록 비슷한 벡터 값을 가질 것이라는 공통된 가정을 전제\n","\n","- 두 방법 모두 윈도우의 크기가 주어지면, 특정 단어를 기준으로 윈도우 내의 주변 단어들을 사용하여 단어 임베딩을 학습\n","- 윈도우 내에서의 위치는 고려하지 않으며, 그렇다고 해서 단어의 위치 정보를 무시하지는 않음\n","    - 윈도우 자체가 단어의 위치 정보를 내포하기 때문\n","    - 문장 내 단어의 위치에 따라서 윈도우에 포함되는 단어가 달라짐\n","\n","### 6.4.1 알고리즘 개요 : CBOW 방식과 skip-gram 방식\n","\n","- CBOW : 주변에 나타나는 단어들을 원핫 인코딩된 벡터로 입력받아 해당 단어를 예측하게 함\n","- Skip-gram : 대상 단어를 원핫 인코딩된 벡터로 입력받아 주변에 나타나는 단어를 예측하는 네트워크를 구성해 단어 임베딩 벡터를 학습\n","- 보통 Skip-gram 이 CBOW 보다 성능이 뛰어난 것으로 알려져 있으며 더 널리 쓰임\n","\n","### 6.4.2 상세 훈련 방식\n","\n","- Skip-gram 방식\n","- MLE 를 통해 다음 수식의 argmax 내의 수식을 최대로 하는 파라미터 $\\theta$ 를 찾음\n","\n","- $w_{t}$ 가 주어졌을 때, 앞뒤 n 개의 단어 $(w_{t-\\frac{n}{2}}, ..., w_{t+\\frac{n}{2}})$ 를 예측하도록 훈련된다. 이때 윈도우의 크기는 $n$\n","\n","$$\\hat{\\theta} = \\$$"],"metadata":{"id":"BagOQFstwA3N"}},{"cell_type":"markdown","source":["## 6.6 word2vec 예제\n","\n","### 6.6.1 FastText 를 활용한 단어 임베딩 벡터 학습\n","\n"],"metadata":{"id":"Tprw2m7RwA6z"}},{"cell_type":"code","source":["# 설치방법\n","!git clone https://github.com/facebookresearch/fastText.git\n","%cd fastText/"],"metadata":{"id":"E61--BbDwA-b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647231153298,"user_tz":-540,"elapsed":1931,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"c6a3eb94-a45e-4cb6-a9aa-1b508e320b60"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'fastText'...\n","remote: Enumerating objects: 3930, done.\u001b[K\n","remote: Counting objects: 100% (76/76), done.\u001b[K\n","remote: Compressing objects: 100% (47/47), done.\u001b[K\n","remote: Total 3930 (delta 28), reused 42 (delta 11), pack-reused 3854\u001b[K\n","Receiving objects: 100% (3930/3930), 8.33 MiB | 16.04 MiB/s, done.\n","Resolving deltas: 100% (2445/2445), done.\n","/content/fastText/fastText\n","\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n"]}]},{"cell_type":"code","source":["!pip install"],"metadata":{"id":"-MqebTlmwBEz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647231198656,"user_tz":-540,"elapsed":712,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"d4d02cd2-1742-40b0-8d88-986f1e215897"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"1dMfFiZSwBIC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647231188665,"user_tz":-540,"elapsed":268,"user":{"displayName":"손희락","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3Gnwu5KqtJnsIScT6lnXAj-wVzbCkZkHGGPK9gA=s64","userId":"06901493583563790110"}},"outputId":"eeef97f3-527c-4105-f457-209f842ffa2e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["alignment\t\t   fastText\t\t    runtests.py\n","classification-example.sh  fasttext.pc.in\t    scripts\n","classification-results.sh  get-wikimedia.sh\t    setup.cfg\n","CMakeLists.txt\t\t   LICENSE\t\t    setup.py\n","CODE_OF_CONDUCT.md\t   Makefile\t\t    src\n","CONTRIBUTING.md\t\t   MANIFEST.in\t\t    tests\n","crawl\t\t\t   python\t\t    webassembly\n","docs\t\t\t   quantization-example.sh  website\n","download_model.py\t   README.md\t\t    wikifil.pl\n","eval.py\t\t\t   reduce_model.py\t    word-vector-example.sh\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"Bk7SVOpswBLR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ew8ZZfJGwBOy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"MyXdNye7wBRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"P65v7tyHwBUy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"_MuSfByVwBZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"DiHTOPNewBfa"},"execution_count":null,"outputs":[]}]}